models in statistics
machine learning

linear regression model
    predicted variable is quantitative (or metric).
    
considered as a building block of several other methods

simple and multiple linear regression, logistic regression, ANOVA, ANCOVA
    variations of the same underlying motif, the linear regression

Linear regression models
Simple | Robust | Hierarchical | Polynomial | Multiple linear regression
Interactions

--------------------------------------------------------------------------
Simple linear regression
    continuous variable represented using real numbers
        dependent/ independent, predicted, or outcome/ input variable
        model how this dependent variable depends on one or more variable
        independent variable can be continuous or "categorical".

        "one/ more than one" independent variable

        Model the relationship between factors
            linear? How strong? strongest effect factors? prediction accurate?

--------------------------------------------------------------------------
machine learning connection
    automatically learn patterns in data
        to predict future data or to take decisions in a state of uncertainty
    regression problem is supervised learning
        mapping from x to y (y being a continuous variable)
        how to generalize these observations

--------------------------------------------------------------------------
core of linear regression
    linear relation: slope, intercept
    several ways to find the parameters
        least squares fitting

    Probabilistically, a linear regression model can be expressed as Gaussian distribution
    set prior distributions for unknow values
        ~ same estimates as using the least squares method
        "If we want to use really strong priors around some specific value 
        for the standard deviation we can use the gamma distribution"

    synthetic data, stochastic variable.

--------------------------------------------------------------------------
Linear models and high autocorrelation
    improve ugly autocorrelation and poor sampling, low number of effective samples
    ?? assumptions, mean x or mean y, line-fitting process ~ change slope or intercept

    "shape of the posterior ~ diagonal space"
        Metropolis-Hastings => problematic

PAGE 101
--------------------------------------------------------------------------
Modifying the data before running
    simple solution to our problem is to center the x data
        "Centering data with pivot point"


--------------------------------------------------------------------------
Changing the sampling method
    NUTS has fewer difficulties than Metropolis in sampling
        such restricted diagonal spaces
    NUTS can be slower than Metropolis per step, 
        but usually needs far fewer steps to get a reasonable approximation to the posterior

--------------------------------------------------------------------------
Interpreting and visualizing the posterior
    average line that fits the data together with the average mean values
    a semitransparent band to illustrate the Highest Posterior Density (HPD) interval
--------------------------------------------------------------------------
Pearson correlation coefficient

--------------------------------------------------------------------------
Pearson coefficient from a multivariate Gaussian

--------------------------------------------------------------------------
Robust linear regression

--------------------------------------------------------------------------
Hierarchical linear regression

--------------------------------------------------------------------------
Correlation, causation, and the messiness of life

--------------------------------------------------------------------------
Polynomial regression

--------------------------------------------------------------------------
Interpreting the parameters of a polynomial regression

--------------------------------------------------------------------------
Polynomial regression â€“ the ultimate model?

--------------------------------------------------------------------------
Multiple linear regression

--------------------------------------------------------------------------
Confounding variables and redundant variables

--------------------------------------------------------------------------
Multicollinearity or when the correlation is too high

--------------------------------------------------------------------------
Masking effect variables

--------------------------------------------------------------------------
The GLM module